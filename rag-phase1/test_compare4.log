2025-12-09 21:02:42,027 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-12-09 21:02:44,517 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions "HTTP/1.1 200 OK"

✓ Loaded 49 documents

=== Filtered retrieval (source_url constrained) ===
- 1. source=https://developers.llamaindex.ai/python/framework/understanding/rag/, score=0.573
  snippet: [install LlamaIndex](/python/framework/getting_started/installation) and complete the [starter tutorial](/python/framework/getting_started/starter_example) befo...

================================================================================
COMPARISON: Different Retrieval Strategies
================================================================================

[1/3] Vector-only retrieval...

=== Strategy 1: Vector-only ===
RAG 系统的核心价值在于能够有效地结合检索和生成的能力，从而提供准确和相关的答案。这种方法利用外部知识库来增强生成模型的输出，使得回答更加丰富和信息量大。

主要挑战包括确保检索到的信息的准确性和相关性，以及如何有效地整合这些信息以生成流畅且自然的回答。此外，处理多样化的数据源和保持系统的高效性也是需要克服的重要问题。 [Source: https://developers.llamaindex.ai/python/framework/understanding/rag/]

Retrieved sources:
- 1. score=0.539 source=https://developers.llamaindex.ai/python/framework/understanding/rag/

[2/3] Hybrid retrieval (Vector + BM25)...
Traceback (most recent call last):
  File "/Users/lamsumchat/Documents/coding_projects/playground/ai_tutorials/agentalpha/rag_demo.py", line 315, in <module>
    main()
    ~~~~^^
  File "/Users/lamsumchat/Documents/coding_projects/playground/ai_tutorials/agentalpha/rag_demo.py", line 307, in main
    compare_retrieval_strategies(index, QUESTION)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/Users/lamsumchat/Documents/coding_projects/playground/ai_tutorials/agentalpha/rag_demo.py", line 259, in compare_retrieval_strategies
    hybrid_retriever = create_hybrid_retriever(index)
  File "/Users/lamsumchat/Documents/coding_projects/playground/ai_tutorials/agentalpha/rag_demo.py", line 194, in create_hybrid_retriever
    bm25_retriever = BM25Retriever.from_defaults(
        nodes=valid_nodes,
        similarity_top_k=5
    )
  File "/Users/lamsumchat/Documents/coding_projects/playground/ai_tutorials/agentalpha/.venv/lib/python3.13/site-packages/llama_index/retrievers/bm25/base.py", line 173, in from_defaults
    raise ValueError("Please pass exactly one of index, nodes, or docstore.")
ValueError: Please pass exactly one of index, nodes, or docstore.
